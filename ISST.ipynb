{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Environment Setup \n",
    "\n",
    "Welcome to the Illinois System Simulation Toolkit (ISST) for AE 443! This notebook will walk you through connecting the various technical, cost, and schedule analyses necessary for your design project. First, let's check that you have all the necessary libraries installed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4106da22c01cc0d1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import pint\n",
    "Units = pint.UnitRegistry()\n",
    "Units.default_format = '~P'\n",
    "Units.define('EUR = [currency]')\n",
    "Units.define('USD = 0.91 * EUR')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69b1cd32b4f4d3f7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the above cell triggered an error, you're most likely missing some of the required libraries. You can either install them yourself, or run the following cell to install them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95955295f197bb8b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install -U numpy pandas matplotlib arviz pymc pint"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0c65c447a2a00a7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once you have the required libraries installed and imported, you can proceed to the next step."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12dad917b4c8dfec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Creating the ISST Model Context\n",
    "\n",
    "Throughout this notebook, we'll be building up a PyMC model context for relating all the parts of your design system together. As such, whenever you want to create a new variable or element of the overall design system, you'll do it within the context:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a783095ce05a5f5d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ISST_Model_Context = pm.Model()\n",
    "\n",
    "with ISST_Model_Context:\n",
    "    P1 = pm.Normal('Parameter Name', mu=0, sigma=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9517e0cd4a000071",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above cell, we've created a parameter, and characterized our uncertainty about it as a normal distribution with mean 0 and standard deviation 1. Note that it has both a variable name 'P1' which will be used to refer to it throughout the code, but it also has a plain language reference to it, 'Parameter Name'. The tag is what will show up in the charts and other reports that will be generated by ISST, so feel free to mix and match your variable names as makes it easiest for you to read the code, while using the tags to determine how they'll show up outside of the code.\n",
    "\n",
    "Because the parameter was created in the ISST model context (by indenting it beneath the `with ISST_Model_Conxtext` line), ISST knows that the parameter is a part of the overall design system, and it will keep track of its relationship to other parts of the design system."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "285ee8588ad8456"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Creating Risk Tables\n",
    "\n",
    "ISST wraps around PyMC models, asking you for just a few plain language properties of your design system. Below is the definition of the Risk Table Class:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "caafe9a3182f6105"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class Risk_Table:\n",
    "    \n",
    "    # Name of the Risk Table\n",
    "    name: str = field(init = True)\n",
    "    \n",
    "    # Units of the impact the Risk Table tracks, e.g. 'kg/m^2' using pint's unit registry:\n",
    "    # https://pint.readthedocs.io/en/stable/user/formatting.html \n",
    "    risk_units: str = field(init = True)\n",
    "    \n",
    "    # Severity level breakpoints. Each breakpoint corresponds to the point at which the risk table assigns a new utility level.\n",
    "    # Defined in ascending order of impact. e.g. [0., 6., 12.] for months of schedule delay or [1., 5., 10.] for millions\n",
    "    # of euros in cost impact. Defaults to five levels capturing a range of 0-10+\n",
    "    utility_breakpoints: list[float] = field(init = True,\n",
    "                                             default_factory = lambda: [0.,\n",
    "                                                                        2.5,\n",
    "                                                                        5.,\n",
    "                                                                        7.5,\n",
    "                                                                        10.])\n",
    "    \n",
    "    # Utility associated with each level of impact. Should be the same length as `utility_breakpoints`. Each entry\n",
    "    # indicates the utility associated with exceeding that breakpoint. e.g. [-1., -3., -5.]. Defaults to a range of 0 to -7.\n",
    "    utilities: list[float] = field(init = True,\n",
    "                                   default_factory = lambda: [0.,\n",
    "                                                              -1.,\n",
    "                                                              -3.,\n",
    "                                                              -5.,\n",
    "                                                              -7.])\n",
    "    \n",
    "    utility_names: list[str] = field(init=True,\n",
    "                                     default_factory = lambda: ['None',\n",
    "                                                                'Negligible',\n",
    "                                                                'Moderate',\n",
    "                                                                'Critical',\n",
    "                                                                'Catastrophic'])\n",
    "        \n",
    "    # Discrete probability levels to be associated with each risk level.\n",
    "    # Defaults to the geometric means of the probability ranges in ICD 203.\n",
    "    probability_levels: list = field(init=True,\n",
    "                                     default_factory = lambda: [0.022,\n",
    "                                                                0.100,\n",
    "                                                                0.300,\n",
    "                                                                0.497,\n",
    "                                                                0.663,\n",
    "                                                                0.87,\n",
    "                                                                0.97])\n",
    "    \n",
    "    # Plain language description of each level in the probability range specification.\n",
    "    probability_names: list[str] = field(init=True,\n",
    "                                         default_factory=lambda:['Remote',\n",
    "                                                                 'Very Unlikely',\n",
    "                                                                 'Unlikely',\n",
    "                                                                 'Roughly Even Chance',\n",
    "                                                                 'Likely',\n",
    "                                                                 'Very Likely',\n",
    "                                                                 'Almost Certain'])\n",
    "    \n",
    "    # Logistic parameters for each level of impact\n",
    "    L : float = field(init=True, default=10.0)\n",
    "    k : float = field(init=True, default=1.0)\n",
    "    x0: float = field(init=True, default=0.0)\n",
    "    \n",
    "    def __post_init__(self):        \n",
    "        \n",
    "        # Check that utility specification is well-formed\n",
    "        assert len(self.utility_breakpoints) == len(self.utilities)\n",
    "        assert len(self.utility_breakpoints) == len(self.utility_names)\n",
    "        \n",
    "        # Check that probability specification is well-formed\n",
    "        assert len(self.probability_levels) == len(self.probability_names)\n",
    "        assert np.array(self.probability_levels).min() >= 0.0\n",
    "        assert (np.array(self.probability_levels).max() <= 1.0)\n",
    "        assert np.all(np.diff(np.array(self.probability_levels)))\n",
    "        \n",
    "        logistic_params = self.fit_utilities()\n",
    "        self.L = logistic_params[0][0]\n",
    "        self.k = logistic_params[0][1]\n",
    "        self.x0 = logistic_params[0][2]\n",
    "\n",
    "            \n",
    "    def _utility(self,\n",
    "                impact,\n",
    "                L = 10.,\n",
    "                k = 1.,\n",
    "                x0 = 0.,\n",
    "                mode = 'logistic',\n",
    "                u_func = lambda x:x):\n",
    "        if mode == 'discrete':\n",
    "            bps = np.atleast_1d(self.utility_breakpoints)\n",
    "            i_arr = np.atleast_2d(impact)\n",
    "            return np.array([self.utilities[i] for i in\n",
    "                    np.sum(\n",
    "                        np.tile(bps,i_arr.shape[1]).reshape((i_arr.shape[1],bps.shape[0])) < i_arr.T,\n",
    "                    axis=1) - 1\n",
    "            ])\n",
    "        if mode == 'logistic':\n",
    "            return np.array(L/(1 + np.exp(-k*(impact - x0))))\n",
    "        if mode == 'custom':\n",
    "            return u_func(impact)\n",
    "    \n",
    "    # Fit a logistics function to the utility levels. Runs by default when the risk table is created.\n",
    "    # Can be run again if the utility levels are redefined.\n",
    "    def fit_utilities(self):\n",
    "\n",
    "        u_func = lambda impact, L, k, x0:self._utility(impact,\n",
    "                                                       mode='logistic',\n",
    "                                                       L=L,\n",
    "                                                       k=k,\n",
    "                                                       x0=x0)\n",
    "        params = curve_fit(u_func,\n",
    "                           xdata=np.array(self.utility_breakpoints),\n",
    "                           ydata=np.array(self.utilities))\n",
    "        \n",
    "        return params\n",
    "\n",
    "\n",
    "    # Evaluate the utility of a given impact level assuming discrete breakpoints and utility levels.\n",
    "    def discrete_utility(self,\n",
    "                         impact):\n",
    "        \n",
    "        return self._utility(impact,\n",
    "                             mode='discrete')\n",
    "    \n",
    "    # Evaluate the utility of a given impact level assuming a logistic utility function.\n",
    "    def logistic_utility(self,\n",
    "                         impact):\n",
    "        \n",
    "        return self._utility(impact,\n",
    "                             mode='logistic',\n",
    "                             L = self.L,\n",
    "                             k = self.k,\n",
    "                             x0 = self.x0)\n",
    "    \n",
    "    # Evaluate the utility of a given impact level using a custom utility function.\n",
    "    def custom_utility(self,\n",
    "                       impact,\n",
    "                       utility_function):\n",
    "        \n",
    "        return self._utility(impact,\n",
    "                             mode='custom',\n",
    "                             u_func = utility_function)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d83a6f2e480e9a46",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's recreate the Schedule Risk Table from class:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "786d35f0118cf0a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Schedule_Risk_Table = Risk_Table(name='Schedule',\n",
    "                                 risk_units='months',\n",
    "                                 utility_breakpoints=[0., 1., 6., 24.,],\n",
    "                                 utilities=[-1., -3., -5., -9.],\n",
    "                                 utility_names=['<1 month', '1-6 months', '6 months - 2 years', '>2 years'])\n",
    "\n",
    "from pprint import pprint as pp\n",
    "pp(Schedule_Risk_Table)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85bf73a6e1e5ee24",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Risk Tables will be used through ISST, but probably the most imporant thing is their implict definition of a utility function. Risk tables have built in discrete and logistic utility functions, and can also take custom utility functions. First, let's look at the discrete utility function, and see how it evaluates the utility of a 2 month, 12 month, and 36 month delay in the schedule.:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c96ebe499d10e4c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f'Discrete utility of a 2 month delay:  {Schedule_Risk_Table.discrete_utility(2.)}')\n",
    "print(f'Discrete utility of a 12 month delay: {Schedule_Risk_Table.discrete_utility(12.)}')\n",
    "print(f'Discrete utility of a 36 month delay: {Schedule_Risk_Table.discrete_utility(36.)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62219c903090bb7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "When you create a risk table, it automatically fits a logistic utility function to the given utility levels. Let's see how it evaluates the same delays:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bdc64b3215c01de"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f'Logistic utility of a 2 month delay:  {Schedule_Risk_Table.logistic_utility(2.):.2f}.')\n",
    "print(f'Logistic utility of a 12 month delay: {Schedule_Risk_Table.logistic_utility(12.):.2f}.')\n",
    "print(f'Logistic utility of a 36 month delay: {Schedule_Risk_Table.logistic_utility(36.):.2f}.')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4037a5c4fcd4ce0b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that by comparison, the logistic utility function is less harsh on the low end of delay, slightly harsher on the high end, but much harsher in the middle. We can see this by plotting the functions:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2743a0666fcb45aa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "xrange = np.linspace(0., 36., 1000)\n",
    "plt.plot(xrange, Schedule_Risk_Table.discrete_utility(xrange), '-', label='Discrete')\n",
    "plt.plot(xrange, Schedule_Risk_Table.logistic_utility(xrange), '--', label='Logistic')\n",
    "plt.axis((0., 36., -10., 0.))\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d9d91df1cf46806",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's say that after looking at the comparison between the logistic and discrete utility functions, we want to adjust the utility levels of the schedule risk table. We think the 6-24 month category is too broad, and want to split it into two categories:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f32d820bf90315"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Schedule_Risk_Table.utility_breakpoints = [0., 1., 6., 12., 24.]\n",
    "Schedule_Risk_Table.utilities = [-1., -3., -5., -7., -9.]\n",
    "Schedule_Risk_Table.fit_utilities()\n",
    "\n",
    "plt.plot(xrange, Schedule_Risk_Table.discrete_utility(xrange), '-', label='Discrete')\n",
    "plt.plot(xrange, Schedule_Risk_Table.logistic_utility(xrange), '--', label='Logistic')\n",
    "plt.axis((0., 36., -10., 0.))\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3806e7c8cb118bdb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Risk:\n",
    "    name: str = field(init=True)\n",
    "    baseline_likelihood: float = field(init=True)\n",
    "    \n",
    "    # Schedule Risk Parameterers\n",
    "    schedule_risk_minimum_value: float = field(init=True, default=0.0)\n",
    "    schedule_risk_maximum_value: float = field(init=True, default=1.0)\n",
    "    schedule_risk_most_likely_value: float = field(init=True, default=0.5)\n",
    "    \n",
    "    # Cost Risk Parameterers\n",
    "    cost_risk_minimum_value: float = field(init=True, default=0.0)\n",
    "    cost_risk_maximum_value: float = field(init=True, default=1.0)\n",
    "    cost_risk_most_likely_value: float = field(init=True, default=0.5)\n",
    "    \n",
    "    # Technical Risk Parameters\n",
    "    technical_risk_minimum_values: list[float] = field(init=True, default_factory=lambda: [])\n",
    "    technical_risk_maximum_values: list[float] = field(init=True, default_factory=lambda: [])\n",
    "    technical_risk_most_likely_values: list[float] = field(init=True, default_factory=lambda: [])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc27e16d6ab6e84b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 5: Creating Your System\n",
    "\n",
    "Now that we've gone over ISST's risk and risk tables, let's go about combining them into a system:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e003cee7a92f874e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Design_System:\n",
    "    \n",
    "    name: str = field(init=True)\n",
    "    \n",
    "    risks: list[Risk] = field(init=True)\n",
    "    \n",
    "    model_context: pm.Model = field(init=True)\n",
    "    \n",
    "    # System-Wide Schedule Risk Table\n",
    "    schedule_risk_table: Risk_Table = field(init=True)\n",
    "    \n",
    "    # System-Wide Cost Risk Table\n",
    "    cost_risk_table: Risk_Table = field(init=True)\n",
    "    \n",
    "    # System-Wide Technical Risk Tables\n",
    "    technical_risk_tables: list[Risk_Table] = field(init=True)\n",
    "    \n",
    "    def __post_init__(self):            \n",
    "        assert self.schedule_risk_table is not None\n",
    "        assert self.cost_risk_table is not None\n",
    "        assert self.technical_risk_tables is not None\n",
    "        \n",
    "        self.schedule_risk_levels = np.zeros(np.asarray(self.schedule_risk_table.utility_breakpoints).shape[0])\n",
    "        self.cost_risk_levels = np.zeros(np.asarray(self.cost_risk_table.utility_breakpoints).shape[0])\n",
    "        \n",
    "        self.max_tech_risk_sizes = np.zeros((len(self.technical_risk_tables)))\n",
    "        mtrs = 0\n",
    "        for ii, risk_table in enumerate(self.technical_risk_tables):\n",
    "            mtrs = max(mtrs, np.asarray(risk_table.utility_breakpoints).shape[0])\n",
    "            self.max_tech_risk_sizes[ii] = mtrs   \n",
    "    \n",
    "    def generate_system_specification(self):\n",
    "        \n",
    "        rootpath = os.getcwd()\n",
    "        system_path = Path(rootpath, self.name)\n",
    "        os.makedirs(system_path, exist_ok=True)\n",
    "        \n",
    "        schedule_df = pd.DataFrame(data = {'Minimum Schedule Impact': np.zeros(len(self.risks)),\n",
    "                                           'Maximum Schedule Impact': np.zeros(len(self.risks)),\n",
    "                                           'Most Likely Schedule Impact': np.zeros(len(self.risks))},\n",
    "                                   index = self.risks)\n",
    "        \n",
    "        with open(Path(system_path,f'{self.name} Schedule Risks.csv'), 'w') as f:\n",
    "            schedule_df.to_csv(f, index=True, header=True)\n",
    "        \n",
    "        cost_df = pd.DataFrame(data = {'Minimum Cost Impact': np.zeros(len(self.risks)),\n",
    "                                       'Maximum Cost Impact': np.zeros(len(self.risks)),\n",
    "                                       'Most Likely Cost Impact': np.zeros(len(self.risks))},\n",
    "                               index=self.risks)\n",
    "        \n",
    "        with open(Path(system_path,f'{self.name} Cost Risks.csv'), 'w') as f:\n",
    "            cost_df.to_csv(f, index=True, header=True)\n",
    "        \n",
    "        for tech_risk in self.technical_risk_tables:\n",
    "            tech_risk_df = pd.DataFrame(data = {f'Minimum {tech_risk.name} Impact': np.zeros(len(self.risks)),\n",
    "                                                f'Maximum {tech_risk.name} Impact': np.zeros(len(self.risks)),\n",
    "                                                f'Most Likely {tech_risk.name} Impact': np.zeros(len(self.risks))},\n",
    "                                        index=self.risks)\n",
    "            \n",
    "            with open(Path(system_path,f'{self.name} {tech_risk.name} Risks.csv'), 'w') as f:\n",
    "                tech_risk_df.to_csv(f, index=True, header=True)\n",
    "        \n",
    "        return\n",
    "            \n",
    "    def read_system_specification(self):\n",
    "        \n",
    "        rootpath = os.getcwd()\n",
    "        system_path = Path(rootpath, self.name)\n",
    "        \n",
    "        with open(Path(system_path, f'{self.name} Schedule Risks.csv'), 'r') as f:\n",
    "            schedule_df = pd.read_csv(f)\n",
    "        \n",
    "        with open(Path(system_path, f'{self.name} Cost Risks.csv'), 'r') as f:\n",
    "            cost_df = pd.read_csv(f)\n",
    "            \n",
    "        for risk in self.risks:\n",
    "                \n",
    "                risk.schedule_risk_minimum_value        = schedule_df.loc[risk.name, 'Minimum Schedule Impact']\n",
    "                risk.schedule_risk_maximum_value        = schedule_df.loc[risk.name, 'Maximum Schedule Impact']\n",
    "                risk.schedule_risk_most_likely_value    = schedule_df.loc[risk.name, 'Most Likely Schedule Impact']\n",
    "                \n",
    "                risk.cost_risk_minimum_value            = cost_df.loc[risk.name, 'Minimum Cost Impact']\n",
    "                risk.cost_risk_maximum_value            = cost_df.loc[risk.name, 'Maximum Cost Impact']\n",
    "                risk.cost_risk_most_likely_value        = cost_df.loc[risk.name, 'Most Likely Cost Impact']\n",
    "            \n",
    "        for tech_risk in self.technical_risk_tables:\n",
    "            \n",
    "            with open(Path(system_path, f'{self.name} {tech_risk.name} Risks.csv'), 'r') as f:\n",
    "                tech_risk_df = pd.read_csv(f)\n",
    "            \n",
    "            for risk in self.risks:\n",
    "                \n",
    "                risk.technical_risk_minimum_values.append(tech_risk_df.loc[risk.name, f'Minimum {tech_risk.name} Impact'])\n",
    "                risk.technical_risk_maximum_values.append(tech_risk_df.loc[risk.name, f'Maximum {tech_risk.name} Impact'])\n",
    "                risk.technical_risk_most_likely_values.append(tech_risk_df.loc[risk.name, f'Most Likely {tech_risk.name} Impact'])\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def analyze_system(self):\n",
    "        \n",
    "        risk_schedule_mins = []\n",
    "        risk_schedule_maxs = []\n",
    "        risk_schedule_mls = []\n",
    "        \n",
    "        risk_cost_mins = []\n",
    "        risk_cost_maxs = []\n",
    "        risk_cost_mls = []\n",
    "        \n",
    "        for risk in self.risks:\n",
    "            risk_schedule_mins.append(risk.schedule_risk_minimum_value)\n",
    "            risk_schedule_maxs.append(risk.schedule_risk_maximum_value)\n",
    "            risk_schedule_mls.append(risk.schedule_risk_most_likely_value)\n",
    "            \n",
    "            risk_cost_mins.append(risk.cost_risk_minimum_value)\n",
    "            risk_cost_maxs.append(risk.cost_risk_maximum_value)\n",
    "            risk_cost_mls.append(risk.cost_risk_most_likely_value)\n",
    "            \n",
    "        \n",
    "        s_min = min(risk_schedule_mins)\n",
    "        s_max = max(risk_schedule_maxs)\n",
    "        s_rng = s_max - s_min\n",
    "        \n",
    "        s_min_arr = (np.asarray(risk_schedule_mins) - s_min)/s_rng\n",
    "        s_max_arr = (np.asarray(risk_schedule_maxs) - s_min)/s_rng\n",
    "        s_ml_arr = (np.asarray(risk_schedule_mls) - s_min)/s_rng\n",
    "        \n",
    "        s_mu = (s_min_arr + 4 * s_ml_arr + s_max_arr) / 6\n",
    "        s_sigma = np.sqrt((s_mu - s_min_arr)*(s_max_arr - s_mu)/7)\n",
    "        \n",
    "        c_min = min(risk_cost_mins)\n",
    "        c_max = max(risk_cost_maxs)\n",
    "        c_rng = c_max - c_min\n",
    "        \n",
    "        c_min_arr = (np.asarray(risk_cost_mins) - c_min)/c_rng\n",
    "        c_max_arr = (np.asarray(risk_cost_maxs) - c_min)/c_rng\n",
    "        c_ml_arr = (np.asarray(risk_cost_mls) - c_min)/c_rng\n",
    "        \n",
    "        c_mu = (c_min_arr + 4 * c_ml_arr + c_max_arr) / 6\n",
    "        c_sigma = np.sqrt((c_mu - c_min_arr)*(c_max - c_mu_arr)/7)\n",
    "        \n",
    "        tech_risk_mins = np.zeros((len(self.risks), len(self.technical_risk_tables)))\n",
    "        tech_risk_maxs = np.zeros((len(self.risks), len(self.technical_risk_tables)))\n",
    "        tech_risk_mls = np.zeros((len(self.risks), len(self.technical_risk_tables)))\n",
    "        \n",
    "        t_mins = np.zeros(len(self.technical_risk_tables))\n",
    "        t_maxs = np.zeros(len(self.technical_risk_tables))\n",
    "        t_mls = np.zeros(len(self.technical_risk_tables))\n",
    "        \n",
    "        t_mus = np.zeros(len(self.technical_risk_tables))\n",
    "        t_sigmas = np.zeros(len(self.technical_risk_tables))\n",
    "        \n",
    "        for jj, tech_risk in enumerate(self.technical_risk_tables):\n",
    "            for ii, risk in enumerate(self.risks):    \n",
    "                tech_risk_mins[ii, jj] = risk.technical_risk_minimum_values[jj]\n",
    "                tech_risk_maxs[ii, jj] = risk.technical_risk_maximum_values[jj]\n",
    "                tech_risk_mls[ii, jj] = risk.technical_risk_most_likely_values[jj]\n",
    "            \n",
    "            t_mins[jj] = min(tech_risk_mins[:, jj])\n",
    "            t_maxs[jj] = max(tech_risk_maxs[:, jj])\n",
    "            t_mls[jj] = max(tech_risk_mls[:, jj])\n",
    "            \n",
    "            t_rngs = t_maxs - t_mins\n",
    "            \n",
    "            t_mins_scaled = (np.asarray(tech_risk_mins[:, jj]) - t_mins[jj])/t_rngs[jj]\n",
    "            t_maxs_scaled = (np.asarray(tech_risk_maxs[:, jj]) - t_mins[jj])/t_rngs[jj]\n",
    "            t_mls_scaled = (np.asarray(tech_risk_mls[:, jj]) - t_mins[jj])/t_rngs[jj]\n",
    "            \n",
    "            t_mus[jj] = (t_mins_scaled[jj] + 4 * t_mls_scaled[ jj] + t_maxs_scaled[jj]) / 6\n",
    "            t_sigmas[jj] = np.sqrt((t_mus[jj] - t_mins_scaled[jj])*(t_maxs_scaled[jj] - t_mus[jj])/7)\n",
    "        \n",
    "        with self.model_context:\n",
    "            schedule_vars = pm.Deterministic('Schedule',\n",
    "                                             pm.Beta('Schedule_Scaled', mu=s_mu, sigma=s_sigma, shape=len(self.risks)) * s_rng + s_min)\n",
    "            cost_vars = pm.Deterministic('Cost',\n",
    "                                         pm.Beta('Cost_Scaled', mu=c_mu, sigma=c_sigma, shape=len(self.risks)) * c_rng + c_min)\n",
    "            technical_vars = pm.Deterministic(\n",
    "                pm.Beta('Technical_Scaled', mu=t_mus, sigma=t_sigmas, shape=(len(self.risks), len(self.technical_risk_tables))) * t_rngs + t_mins)\n",
    "            \n",
    "            risk_priors = []\n",
    "            for ii, risk in enumerate(self.risks):\n",
    "                risk_priors.append(risk.basline_likelihood)\n",
    "                \n",
    "            total_schedule_impact = pm.math.dot(schedule_vars, np.asarry(risk_priors))\n",
    "            total_cost_impact = pm.math.dot(cost_vars, np.asarry(risk_priors))\n",
    "            total_technical_impact = pm.math.dot(technical_vars.T, np.asarry(risk_priors)).T\n",
    "            \n",
    "            idata = pm.sample()  \n",
    "        \n",
    "        return idata\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a013dcd3f16da84",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "strike = Risk(name='Strike', baseline_likelihood=0.02)\n",
    "flood = Risk(name='Flood', baseline_likelihood=0.20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9461a96f27b1b84e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Cost_Risk_Table = Risk_Table(name='Cost', risk_units='EUR')\n",
    "Weight_Risk_Table = Risk_Table(name='Weight', risk_units='kg')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "541ade6cb9f4755b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "System = Design_System(name = 'Demo',\n",
    "                       risks=[strike, flood],\n",
    "                       model_context=ISST_Model_Context,\n",
    "                       schedule_risk_table=Schedule_Risk_Table,\n",
    "                       cost_risk_table=Cost_Risk_Table,\n",
    "                       technical_risk_tables=[Tech_Risk_Table])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e7f8f3598678e3a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "814d1f671962f157"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
